# ------------------------------------------------------------
# ê²½ìŸì‚¬ ë¹„êµ ì—ì´ì „íŠ¸ (ë‹´ë‹¹: ì •ê´‘ì§„)
# - ê¸°ì¡´ ê¸°ìˆ  ìš”ì•½ ì—ì´ì „íŠ¸ í…œí”Œë¦¿ì„ ìµœëŒ€í•œ ìœ ì§€
# - ê¸°ìˆ  ìš”ì•½ ì—ì´ì „íŠ¸ì˜ outputì„ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ ê²½ìŸì‚¬ ë¹„êµ ìˆ˜í–‰
# - TavilySearchë¥¼ í™œìš©í•œ ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ê²½ìŸì‚¬ ì •ë³´ ìˆ˜ì§‘
# - 5ì  ì²™ë„ í‰ê°€ ì¶œë ¥
# ------------------------------------------------------------

import os
import json
from dotenv import load_dotenv

# ë¡œê¹…/ì„¸ì…˜ ì„¤ì •
from langchain_teddynote import logging as tnote_logging
tnote_logging.langsmith("CH15-Competitor-Analysis")

# Core imports
from typing import Annotated, Literal, Sequence, TypedDict
from pydantic import BaseModel, Field

# LangChain imports
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import PromptTemplate, ChatPromptTemplate
from langchain_core.runnables import RunnableConfig
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI

# LangGraph imports
from langgraph.graph import END, START, StateGraph
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode, tools_condition

# Custom imports (teddynote)
from langchain_teddynote.messages import random_uuid, stream_graph
from langchain_teddynote.models import LLMs, get_model_name
from langchain_teddynote.tools.tavily import TavilySearch

# -----------------------------
# 0) í™˜ê²½ ë³€ìˆ˜/ëª¨ë¸ ì„¤ì •
# -----------------------------
load_dotenv()
MODEL_NAME = get_model_name(LLMs.GPT_4o_mini)
TAVILY_API_KEY = os.getenv("TAVILY_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# -----------------------------
# 1) ë„êµ¬ ì •ì˜: Tavily Web Search
# -----------------------------
@tool
def search_competitors(query: str) -> str:
    """
    Search for competitors in the same industry/category using Tavily web search.
    Use this to find competing startups and their basic information.
    
    Args:
        query: Search query (e.g., "Qure.ai competitors medical AI imaging")
    
    Returns:
        Competitor information from web search results
    """
    try:
        tavily_tool = TavilySearch()
        search_results = tavily_tool.search(
            query=query,
            topic="general",  # ì¼ë°˜ ì£¼ì œ (ê²½ìŸì‚¬ ì •ë³´)
            days=365,  # ìµœê·¼ 1ë…„ ë‚´ ì •ë³´
            max_results=5,  # ìµœëŒ€ 5ê°œ ê²°ê³¼
            format_output=True,  # ê²°ê³¼ í¬ë§·íŒ…
        )
        
        # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¬¸ìì—´ë¡œ ê²°í•©
        formatted_results = "\n\n".join(search_results)
        return f"Web search results for: {query}\n\n{formatted_results}"
        
    except Exception as e:
        # ì—ëŸ¬ ë°œìƒ ì‹œ ê¸°ë³¸ ë©”ì‹œì§€ ë°˜í™˜
        return f"Error searching for competitors: {str(e)}\nPlease try with a different query."

@tool
def fetch_competitor_details(competitor_name: str, focus_area: str = "technology funding partnerships") -> str:
    """
    Fetch detailed information about a specific competitor using Tavily web search.
    Use this after identifying competitors to get more detailed information.
    
    Args:
        competitor_name: Name of the competitor company
        focus_area: Specific areas to focus on (default: "technology funding partnerships")
    
    Returns:
        Detailed company information from web search
    """
    try:
        tavily_tool = TavilySearch()
        
        # ì—¬ëŸ¬ ì¸¡ë©´ì—ì„œ ê²€ìƒ‰í•˜ì—¬ ì¢…í•©ì ì¸ ì •ë³´ ìˆ˜ì§‘
        queries = [
            f"{competitor_name} technology products features",
            f"{competitor_name} funding investment valuation",
            f"{competitor_name} FDA approval CE mark certification",
            f"{competitor_name} partnerships customers"
        ]
        
        all_results = []
        for query in queries[:2]:  # ì²˜ìŒ 2ê°œ ì¿¼ë¦¬ë§Œ ì‹¤í–‰ (í† í° ì ˆì•½)
            search_results = tavily_tool.search(
                query=query,
                topic="general",
                days=365,
                max_results=3,
                format_output=True,
            )
            all_results.extend(search_results)
        
        formatted_results = "\n\n".join(all_results)
        return f"Detailed information about {competitor_name}:\n\n{formatted_results}"
        
    except Exception as e:
        return f"Error fetching details for {competitor_name}: {str(e)}"

# ë„êµ¬ ë¦¬ìŠ¤íŠ¸
tools = [search_competitors, fetch_competitor_details]

# -----------------------------
# 2) LangGraph State ì •ì˜
# -----------------------------
class AgentState(TypedDict):
    """ì—ì´ì „íŠ¸ ìƒíƒœ ì •ì˜ - ê¸°ì¡´ í…œí”Œë¦¿ ìœ ì§€ + í™•ì¥"""
    messages: Annotated[Sequence[BaseMessage], add_messages]
    startup_info: dict  # ê¸°ìˆ  ìš”ì•½ ì—ì´ì „íŠ¸ì—ì„œ ë°›ì€ ìŠ¤íƒ€íŠ¸ì—… ì •ë³´
    tech_summary: str   # ê¸°ìˆ  ìš”ì•½ ì—ì´ì „íŠ¸ì˜ ì¶œë ¥
    competitor_list: list  # ë°œê²¬ëœ ê²½ìŸì‚¬ ë¦¬ìŠ¤íŠ¸
    competitor_analysis: dict  # ê²½ìŸì‚¬ ë¹„êµ ë¶„ì„ ê²°ê³¼
    final_score: int  # ìµœì¢… 5ì  ì²™ë„ ì ìˆ˜

class CompetitorGrade(BaseModel):
    """ê²½ìŸì‚¬ ì •ë³´ ì¶©ë¶„ì„± í‰ê°€ ìŠ¤í‚¤ë§ˆ"""
    binary_score: str = Field(
        description="Response 'yes' if sufficient competitor information is gathered, or 'no' if more information is needed."
    )

class CompetitiveScore(BaseModel):
    """ê²½ìŸë ¥ í‰ê°€ ì ìˆ˜ ìŠ¤í‚¤ë§ˆ"""
    score: int = Field(
        description="Competitive score from 1 to 5",
        ge=1,
        le=5
    )
    reasoning: str = Field(
        description="Reasoning for the score"
    )

# -----------------------------
# 3) ê²½ìŸì‚¬ ì •ë³´ ì¶©ë¶„ì„± í‰ê°€
# -----------------------------
def grade_competitor_info(state) -> Literal["analyze", "search_more"]:
    """ê²½ìŸì‚¬ ì •ë³´ê°€ ì¶©ë¶„í•œì§€ í‰ê°€ (ê¸°ì¡´ grade_documents íŒ¨í„´)"""
    model = ChatOpenAI(temperature=0, model=MODEL_NAME, streaming=True)
    llm_with_tool = model.with_structured_output(CompetitorGrade)

    prompt = PromptTemplate(
        template=(
            "You are evaluating whether sufficient competitor information has been gathered.\n"
            "Startup: {startup_name}\n"
            "Tech Summary: {tech_summary}\n\n"
            "Gathered Information:\n{competitor_info}\n\n"
            "Evaluate if we have enough information about:\n"
            "1. At least 3 competitors identified\n"
            "2. Key technology details for each\n"
            "3. Market position/funding information\n\n"
            "If sufficient, respond 'yes'. If need more details, respond 'no'."
        ),
        input_variables=["startup_name", "tech_summary", "competitor_info"],
    )

    chain = prompt | llm_with_tool

    messages = state["messages"]
    startup_info = state.get("startup_info", {})
    tech_summary = state.get("tech_summary", "")
    competitor_info = messages[-1].content if messages else ""

    scored_result = chain.invoke({
        "startup_name": startup_info.get("name", "Unknown"),
        "tech_summary": tech_summary,
        "competitor_info": competitor_info
    })
    
    score = scored_result.binary_score

    if score.strip().lower() == "yes":
        print("==== [DECISION: SUFFICIENT COMPETITOR INFO] ====")
        return "analyze"
    else:
        print("==== [DECISION: NEED MORE COMPETITOR INFO] ====")
        return "search_more"

# -----------------------------
# 4) Agent ë…¸ë“œ (ë„êµ¬ ì‚¬ìš© íŒë‹¨)
# -----------------------------
def agent(state):
    """ì—ì´ì „íŠ¸ - ê²½ìŸì‚¬ ê²€ìƒ‰ ë„êµ¬ ì‚¬ìš© ê²°ì • (ê¸°ì¡´ agent íŒ¨í„´)"""
    messages = state["messages"]
    model = ChatOpenAI(temperature=0, streaming=True, model=MODEL_NAME)
    model = model.bind_tools(tools)
    response = model.invoke(messages)
    return {"messages": [response]}

# -----------------------------
# 5) Search More ë…¸ë“œ (ì¶”ê°€ ê²€ìƒ‰)
# -----------------------------
def search_more(state):
    """ê²½ìŸì‚¬ ì •ë³´ ë¶€ì¡± ì‹œ ì¶”ê°€ ê²€ìƒ‰ (ê¸°ì¡´ rewrite íŒ¨í„´)"""
    print("==== [SEARCHING MORE COMPETITORS] ====")
    messages = state["messages"]
    startup_info = state.get("startup_info", {})
    competitor_list = state.get("competitor_list", [])

    startup_name = startup_info.get("name", "Unknown")
    category = startup_info.get("category", "AI")
    
    # ì´ì „ ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„
    has_competitor_names = any("competitor" in msg.content.lower() for msg in messages if hasattr(msg, 'content'))
    
    if has_competitor_names and len([msg for msg in messages if "Detailed information" in str(msg.content)]) < 2:
        # ê²½ìŸì‚¬ ì´ë¦„ì€ ìˆì§€ë§Œ ìƒì„¸ ì •ë³´ê°€ ë¶€ì¡±í•œ ê²½ìš°
        msg = [
            HumanMessage(
                content=(
                    f"Get detailed information about the main competitors of {startup_name}. "
                    f"Focus on their technology, FDA/CE certifications, funding rounds, "
                    f"and key partnerships. Search for recent news and updates."
                )
            )
        ]
    else:
        # ê²½ìŸì‚¬ ë¦¬ìŠ¤íŠ¸ ìì²´ê°€ ë¶€ì¡±í•œ ê²½ìš°
        msg = [
            HumanMessage(
                content=(
                    f"Search for the top competitors of {startup_name} in the {category} industry. "
                    f"Find companies that offer similar products or services in medical imaging AI, "
                    f"diagnostic AI, or healthcare AI. Include information about their technology, "
                    f"market position, and funding."
                )
            )
        ]

    model = ChatOpenAI(temperature=0, model=MODEL_NAME, streaming=True)
    response = model.invoke(msg)
    return {"messages": [response]}

# -----------------------------
# 6) Analyze ë…¸ë“œ (ë¹„êµ ë¶„ì„)
# -----------------------------
def analyze(state):
    """ê²½ìŸì‚¬ ë¹„êµ ë¶„ì„ ìˆ˜í–‰"""
    print("==== [ANALYZING COMPETITORS] ====")
    messages = state["messages"]
    startup_info = state.get("startup_info", {})
    tech_summary = state.get("tech_summary", "")
    
    # ìˆ˜ì§‘ëœ ê²½ìŸì‚¬ ì •ë³´ ì¶”ì¶œ
    competitor_info = "\n\n".join([
        msg.content for msg in messages 
        if hasattr(msg, 'content') and isinstance(msg.content, str)
    ])

    prompt = ChatPromptTemplate.from_template(
        """You are a venture capital analyst performing competitive analysis.

**Target Startup:**
Name: {startup_name}
Category: {category}
Technology Summary: {tech_summary}

**Competitor Information:**
{competitor_info}

**Analysis Framework:**
Compare the target startup against competitors across these dimensions:

1. Technology Differentiation (30%)
   - Unique technical capabilities
   - Innovation level
   - Technical barriers

2. Market Entry Barriers (25%)
   - Patents and IP
   - Regulatory approvals (FDA, CE, etc.)
   - Network effects

3. Funding & Growth (20%)
   - Total funding raised
   - Growth trajectory
   - Financial stability

4. Partnerships & Ecosystem (15%)
   - Strategic partnerships
   - Customer base
   - Market penetration

5. Validation & Certification (5%)
   - Clinical validations
   - Regulatory approvals
   - Published research

6. Brand Recognition (5%)
   - Market presence
   - Industry reputation

**Output Format:**
Provide a comprehensive comparison analysis with:
- Key strengths vs competitors
- Key weaknesses vs competitors
- Competitive positioning (Leader/Strong Challenger/Competitive/Weak/Very Weak)
- Specific evidence for each dimension
"""
    )

    llm = ChatOpenAI(model=MODEL_NAME, temperature=0, streaming=True)
    chain = prompt | llm | StrOutputParser()

    response = chain.invoke({
        "startup_name": startup_info.get("name", "Target Startup"),
        "category": startup_info.get("category", "Technology"),
        "tech_summary": tech_summary,
        "competitor_info": competitor_info
    })

    return {"messages": [response], "competitor_analysis": {"analysis": response}}

# -----------------------------
# 7) Evaluate ë…¸ë“œ (5ì  ì²™ë„ í‰ê°€)
# -----------------------------
def evaluate(state):
    """ìµœì¢… ê²½ìŸë ¥ ì ìˆ˜ ì‚°ì¶œ (1-5ì )"""
    print("==== [EVALUATING COMPETITIVE SCORE] ====")
    competitor_analysis = state.get("competitor_analysis", {})
    analysis_text = competitor_analysis.get("analysis", "")

    model = ChatOpenAI(temperature=0, model=MODEL_NAME)
    llm_with_structure = model.with_structured_output(CompetitiveScore)

    prompt = PromptTemplate(
        template=(
            "Based on the competitive analysis below, assign a score from 1 to 5:\n\n"
            "5 (Outstanding): Clear competitive advantage across most dimensions\n"
            "4 (Strong): Notable advantages, minor weaknesses\n"
            "3 (Competitive): On par with competitors, some differentiation\n"
            "2 (Weak): Behind competitors in most areas\n"
            "1 (Very Weak): Significant disadvantages, unclear differentiation\n\n"
            "Analysis:\n{analysis}\n\n"
            "Provide score (1-5) and reasoning."
        ),
        input_variables=["analysis"],
    )

    chain = prompt | llm_with_structure
    result = chain.invoke({"analysis": analysis_text})

    print(f"==== COMPETITIVE SCORE: {result.score}/5 ====")
    print(f"Reasoning: {result.reasoning}")

    return {
        "final_score": result.score,
        "competitor_analysis": {
            **competitor_analysis,
            "score": result.score,
            "reasoning": result.reasoning
        }
    }

# -----------------------------
# 8) ê·¸ë˜í”„ êµ¬ì„±
# -----------------------------
def build_graph():
    """LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì„± (ê¸°ì¡´ í…œí”Œë¦¿ íŒ¨í„´)"""
    workflow = StateGraph(AgentState)

    # ë…¸ë“œ ì¶”ê°€
    workflow.add_node("agent", agent)
    retrieve = ToolNode(tools)
    workflow.add_node("retrieve", retrieve)
    workflow.add_node("search_more", search_more)
    workflow.add_node("analyze", analyze)
    workflow.add_node("evaluate", evaluate)

    # ì—£ì§€ ì •ì˜
    workflow.add_edge(START, "agent")
    
    # agent í›„ ì¡°ê±´ë¶€ ë¶„ê¸°
    workflow.add_conditional_edges(
        "agent",
        tools_condition,
        {"tools": "retrieve", END: END},
    )
    
    # retrieve í›„ ì •ë³´ ì¶©ë¶„ì„± í‰ê°€
    workflow.add_conditional_edges(
        "retrieve",
        grade_competitor_info,
        {"analyze": "analyze", "search_more": "search_more"}
    )
    
    # search_more í›„ ë‹¤ì‹œ agentë¡œ
    workflow.add_edge("search_more", "agent")
    
    # analyze í›„ evaluateë¡œ
    workflow.add_edge("analyze", "evaluate")
    
    # evaluate í›„ ì¢…ë£Œ
    workflow.add_edge("evaluate", END)

    return workflow.compile()

# -----------------------------
# 9) ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# -----------------------------
def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    from langchain_teddynote.graphs import visualize_graph

    # Tavily API í‚¤ í™•ì¸
    tavily_key = os.getenv("TAVILY_API_KEY", "")
    if tavily_key.startswith("tvly-placeholder"):
        print("\n" + "="*80)
        print("âš ï¸  ê²½ê³ : Tavily API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        print("ì‹¤ì œ ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ë ¤ë©´ .env íŒŒì¼ì— ë‹¤ìŒì„ ì¶”ê°€í•˜ì„¸ìš”:")
        print("TAVILY_API_KEY=your_actual_tavily_api_key_here")
        print("="*80 + "\n")

    graph = build_graph()
    
    # ê·¸ë˜í”„ ì‹œê°í™”
    visualize_graph(graph)
    print(graph.get_graph().draw_ascii())

    # ì‹¤í–‰ ì„¤ì •
    config = RunnableConfig(
        recursion_limit=25,
        configurable={"thread_id": random_uuid()}
    )

    # ========================================
    # ì˜ˆì‹œ 1: ê¸°ìˆ  ìš”ì•½ ì—ì´ì „íŠ¸ì˜ output ì‹œë®¬ë ˆì´ì…˜
    # ========================================
    startup_info = {
        "name": "Qure.ai",
        "category": "Medical AI Imaging",
        "founded": 2016,
        "location": "India"
    }

    tech_summary = """
    Qure.ai is a medical AI startup specializing in deep learning-based diagnostic solutions 
    for medical imaging. Core technologies include:
    
    1. qXR: Chest X-ray interpretation AI (tuberculosis, pneumonia, lung nodules)
    2. qER: Head CT scan analysis for acute neurological conditions
    3. qTrack: Tuberculosis treatment monitoring
    
    Key Strengths:
    - FDA 510(k) cleared for qXR
    - CE marked for multiple products
    - Deployed in 70+ countries
    - Strong focus on emerging markets
    - Partnerships with major healthcare providers
    
    Technology Stack:
    - Deep learning (CNN-based architectures)
    - Cloud-based platform
    - DICOM integration
    - Automated workflow integration
    """

    initial_message = HumanMessage(
        content=(
            f"Analyze competitors for {startup_info['name']}, "
            f"a {startup_info['category']} startup. "
            f"Search the web to find major competitors and compare their competitive position. "
            f"Focus on medical AI imaging companies with FDA/CE approvals."
        )
    )

    inputs = {
        "messages": [initial_message],
        "startup_info": startup_info,
        "tech_summary": tech_summary,
        "competitor_list": [],
        "competitor_analysis": {},
        "final_score": 0
    }

    print("\n" + "="*80)
    print("ğŸ” ê²½ìŸì‚¬ ë¹„êµ ì—ì´ì „íŠ¸ ì‹¤í–‰ ì‹œì‘ (Tavily Web Search)")
    print("="*80 + "\n")

    # ê·¸ë˜í”„ ì‹¤í–‰ (ìŠ¤íŠ¸ë¦¬ë°)
    stream_graph(
        graph, 
        inputs, 
        config, 
        ["agent", "search_more", "analyze", "evaluate"]
    )

    print("\n" + "="*80)
    print("âœ… ê²½ìŸì‚¬ ë¹„êµ ì—ì´ì „íŠ¸ ì‹¤í–‰ ì™„ë£Œ")
    print("="*80 + "\n")

    # ========================================
    # ìµœì¢… ê²°ê³¼ ì¶œë ¥ í•¨ìˆ˜
    # ========================================
    def print_final_results(final_state):
        """ìµœì¢… ë¶„ì„ ê²°ê³¼ ì¶œë ¥"""
        print("\n" + "="*80)
        print("ğŸ“Š ìµœì¢… ê²½ìŸì‚¬ ë¹„êµ ë¶„ì„ ê²°ê³¼")
        print("="*80)
        
        analysis = final_state.get("competitor_analysis", {})
        score = final_state.get("final_score", 0)
        
        print(f"\nğŸ¯ ê²½ìŸë ¥ ì ìˆ˜: {score}/5")
        print(f"\nğŸ“ í‰ê°€ ê·¼ê±°:\n{analysis.get('reasoning', 'N/A')}")
        print("\n" + "="*80 + "\n")

if __name__ == "__main__":
    main()
