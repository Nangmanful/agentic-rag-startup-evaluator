"""
ì‹œì¥ì„± í‰ê°€ ì—ì´ì „íŠ¸ ë…¸ë“œ í•¨ìˆ˜ë“¤ (v0.2.1)
Reference: 16-AgenticRAG, 21-Agent, 22-LangGraph
"""

import re
from typing import Dict
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser
from langchain_teddynote.evaluator import GroundednessChecker
from langchain_teddynote.tools.tavily import TavilySearch

from agents.state import MarketAnalysisState
from prompts.bessemer_questions import get_bessemer_questions
from prompts.query_rewrite_prompt import get_query_rewrite_prompt
from prompts.scorecard_prompt import get_scorecard_prompt
from utils.rag_tools import setup_rag_pipeline, retrieve_with_sources


# ========== ë…¸ë“œ 1: ì´ˆê¸°í™” ==========
def initialize_analysis(state: MarketAnalysisState) -> Dict:
    """
    [ë…¸ë“œ 1: ì´ˆê¸°í™”] RAG ì—”ì§„ êµ¬ì¶• ë° Bessemer ì§ˆë¬¸ ìƒì„±

    ì‘ì—…:
    1. PDF ë¡œë”©, í…ìŠ¤íŠ¸ ë¶„í• , FAISS ë²¡í„° ìŠ¤í† ì–´ êµ¬ì¶• (1íšŒë§Œ)
    2. Bessemer ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸ ìƒì„±
    3. Stateì— retrieverì™€ ì§ˆë¬¸ ì €ì¥

    Reference: 16-AgenticRAG/01-NaiveRAG.ipynb
    """

    print("\n" + "="*60)
    print(" [MarketAgent] ì´ˆê¸°í™”: RAG ì—”ì§„ êµ¬ì¶• ì‹œì‘")
    print("="*60)

    # 1. RAG íŒŒì´í”„ë¼ì¸ êµ¬ì¶• (í•µì‹¬ ê°œì„ : 1íšŒë§Œ ì‹¤í–‰)
    try:
        retriever = setup_rag_pipeline(state["document_path"])
    except Exception as e:
        print(f" [ERROR] RAG íŒŒì´í”„ë¼ì¸ êµ¬ì¶• ì‹¤íŒ¨: {e}")
        # ì‹¤íŒ¨ ì‹œ ë”ë¯¸ retriever ë°˜í™˜ (ì—ëŸ¬ ì²˜ë¦¬)
        retriever = None

    # 2. Bessemer ì§ˆë¬¸ ìƒì„±
    sub_questions = get_bessemer_questions()

    print(f"\n [ì´ˆê¸°í™”] Bessemer ì§ˆë¬¸ {len(sub_questions)}ê°œ ì¤€ë¹„ ì™„ë£Œ:")
    for i, q in enumerate(sub_questions, 1):
        print(f"  {i}. {q['key']}: {q['question'][:50]}...")

    # 3. State ì—…ë°ì´íŠ¸
    return {
        "retriever": retriever,
        "sub_questions": sub_questions,
        "current_question_idx": 0,
        "rewrite_count": 0,
        "fallback_attempted": False,
        "bessemer_answers": {}
    }


# ========== ë…¸ë“œ 1.5: ì‚°ì—… ë‰´ìŠ¤ ê²€ìƒ‰ (v0.3.0) ==========
def search_industry_news(state: MarketAnalysisState) -> Dict:
    """
    [ë…¸ë“œ 1.5: ì‚°ì—… ë‰´ìŠ¤ ê²€ìƒ‰] ìŠ¤íƒ€íŠ¸ì—… ì‚°ì—…ì˜ ìµœê·¼ ë‰´ìŠ¤ ìˆ˜ì§‘

    ì‘ì—…:
    1. PDFì—ì„œ ì‚°ì—… ì¹´í…Œê³ ë¦¬ ìë™ ì¶”ì¶œ (ì˜ˆ: "Healthcare AI", "Fintech")
    2. 3ê°€ì§€ ë‰´ìŠ¤ ì¿¼ë¦¬ ì‹¤í–‰:
       - ì‹œì¥ ë™í–¥: "{industry} market trends 2025"
       - ê²½ìŸì‚¬: "{industry} startup funding news"
       - ê·œì œ: "{industry} regulation policy changes"
    3. ìµœê·¼ 3ì¼ ë‰´ìŠ¤ë§Œ ìˆ˜ì§‘ (days=3)
    4. ê²°ê³¼ë¥¼ industry_newsì— ì €ì¥

    Reference: 16-AgenticRAG/03-WebSearch.ipynb
    """

    print("\n" + "="*60)
    print(" [MarketAgent] ì‚°ì—… ë‰´ìŠ¤ ê²€ìƒ‰ ì‹œì‘")
    print("="*60)

    # 1. ì‚°ì—… ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ (ê°„ë‹¨í•œ LLM í˜¸ì¶œ)
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

    retriever = state["retriever"]

    if retriever is None:
        print(" [WARNING] Retrieverê°€ ì—†ì–´ ì‚°ì—… ë¶„ë¥˜ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        return {
            "industry_category": "General",
            "industry_news": {
                "industry": "General",
                "search_date": "2025-10-13",
                "news_categories": {}
            }
        }

    # Retrieverë¡œ ì²« í˜ì´ì§€ ê²€ìƒ‰
    try:
        first_docs = retriever.invoke(
            "What industry does this company belong to? medical, fintech, e-commerce, AI, etc."
        )
        from utils.rag_tools import format_docs
        context = format_docs(first_docs)

        prompt = f"""Based on this document, identify the industry category in 2-3 words:

{context[:1000]}

Return ONLY the industry name (e.g., "Healthcare AI", "Fintech", "E-commerce SaaS")"""

        industry = llm.invoke(prompt).content.strip()
        print(f"\n [ì‚°ì—… ë¶„ë¥˜] {industry}")

    except Exception as e:
        print(f" [WARNING] ì‚°ì—… ë¶„ë¥˜ ì‹¤íŒ¨: {e}, ê¸°ë³¸ê°’ ì‚¬ìš©")
        industry = "Technology"

    # 2. Tavily ê²€ìƒ‰ ë„êµ¬ ì´ˆê¸°í™”
    tavily_tool = TavilySearch(max_results=5)

    # 3. 3ê°€ì§€ ë‰´ìŠ¤ ì¿¼ë¦¬ ì‹¤í–‰
    news_queries = {
        "market_trends": f"{industry} market trends growth 2025",
        "competitor_moves": f"{industry} startup funding investment news",
        "regulatory_changes": f"{industry} regulation policy changes"
    }

    industry_news = {
        "industry": industry,
        "search_date": "2025-10-13",
        "news_categories": {}
    }

    for category, query in news_queries.items():
        print(f"\n [ë‰´ìŠ¤ ê²€ìƒ‰] {category}: {query}")

        try:
            search_results = tavily_tool.search(
                query=query,
                topic="news",           # ë‰´ìŠ¤ ì£¼ì œë¡œ í•œì •
                days=3,                 # ìµœê·¼ 3ì¼
                max_results=5,          # ê° ì¹´í…Œê³ ë¦¬ë‹¹ 5ê°œ
                format_output=True      # í¬ë§·íŒ…ëœ ì¶œë ¥
            )

            industry_news["news_categories"][category] = search_results
            print(f" âœ… {len(search_results)}ê°œ ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ")

        except Exception as e:
            print(f" âš ï¸ {category} ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            industry_news["news_categories"][category] = []

    # 4. ìš”ì•½ í†µê³„
    total_news = sum(len(v) for v in industry_news["news_categories"].values())
    print(f"\n [ê²€ìƒ‰ ì™„ë£Œ] ì´ {total_news}ê°œ ì‚°ì—… ë‰´ìŠ¤ ìˆ˜ì§‘")

    return {
        "industry_category": industry,
        "industry_news": industry_news
    }


# ========== ë…¸ë“œ 2: ë‹¤ìŒ ì§ˆë¬¸ ì„ íƒ ==========
def select_next_question(state: MarketAnalysisState) -> Dict:
    """
    [ë…¸ë“œ 2: ì§ˆë¬¸ ì„ íƒ] ë‹¤ìŒ ë¶„ì„í•  Bessemer ì§ˆë¬¸ ì„ íƒ

    Reference: 21-Agent/21-Multi-ReportAgent.ipynb (current_section íŒ¨í„´)
    """

    current_idx = state["current_question_idx"]
    sub_questions = state["sub_questions"]

    if current_idx >= len(sub_questions):
        # ëª¨ë“  ì§ˆë¬¸ ì™„ë£Œ
        print("\nâœ… [ì§ˆë¬¸ ì„ íƒ] ëª¨ë“  Bessemer ì§ˆë¬¸ ë¶„ì„ ì™„ë£Œ!")
        return {}

    # ë‹¤ìŒ ì§ˆë¬¸ ì„ íƒ
    current_q = sub_questions[current_idx]

    print("\n" + "-"*60)
    print(f"ğŸ“ [ì§ˆë¬¸ ì„ íƒ] ({current_idx + 1}/{len(sub_questions)}) {current_q['key']}")
    print(f"   ì§ˆë¬¸: {current_q['question']}")
    print("-"*60)

    # State ì—…ë°ì´íŠ¸
    return {
        "current_question": current_q["question"],
        "rewrite_count": 0,  # ì§ˆë¬¸ì´ ë°”ë€Œë©´ ì¬ì‘ì„± ì¹´ìš´í„° ë¦¬ì…‹
        "fallback_attempted": False  # ì›¹ ê²€ìƒ‰ í”Œë˜ê·¸ë„ ë¦¬ì…‹
    }


# ========== ë…¸ë“œ 3: ë¬¸ì„œ ê²€ìƒ‰ ==========
def retrieve_documents(state: MarketAnalysisState) -> Dict:
    """
    [ë…¸ë“œ 3: ê²€ìƒ‰] Stateì— ì €ì¥ëœ Retrieverë¡œ ë¬¸ì„œ ê²€ìƒ‰

    ê°œì„ ì : retrieverë¥¼ ë§¤ë²ˆ ìƒì„±í•˜ì§€ ì•Šê³  Stateì—ì„œ ì¬ì‚¬ìš©

    Reference: 16-AgenticRAG/01-NaiveRAG.ipynb
    """

    print(f"\n [ë¬¸ì„œ ê²€ìƒ‰] ì§ˆë¬¸: {state['current_question'][:50]}...")

    retriever = state["retriever"]

    if retriever is None:
        print(" [ERROR] Retrieverê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return {"retrieved_docs": "", "is_relevant": "no"}

    # ë¬¸ì„œ ê²€ìƒ‰ (ì¶œì²˜ í¬í•¨)
    try:
        formatted_docs, sources = retrieve_with_sources(
            retriever,
            state["current_question"]
        )

        print(f" [ë¬¸ì„œ ê²€ìƒ‰] {len(sources)}ê°œ ì¶œì²˜ì—ì„œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ ì™„ë£Œ")
        print(f"   ì¶œì²˜: {sources[:3]}")  # ìµœëŒ€ 3ê°œë§Œ ì¶œë ¥

        return {"retrieved_docs": formatted_docs}

    except Exception as e:
        print(f" [ERROR] ë¬¸ì„œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return {"retrieved_docs": "", "is_relevant": "no"}


# ========== ë…¸ë“œ 4: ê´€ë ¨ì„± í‰ê°€ ==========
def grade_relevance(state: MarketAnalysisState) -> Dict:
    """
    [ë…¸ë“œ 4: ê´€ë ¨ì„± í‰ê°€] ê²€ìƒ‰ ê²°ê³¼ê°€ ì§ˆë¬¸ê³¼ ê´€ë ¨ ìˆëŠ”ì§€ í‰ê°€

    Reference: 16-AgenticRAG/02-RelevanceCheck.ipynb
    """

    print(f"\nâš–ï¸ [ê´€ë ¨ì„± í‰ê°€] ê²€ìƒ‰ ê²°ê³¼ í‰ê°€ ì¤‘...")

    # GroundednessChecker ìƒì„± (02-RelevanceCheck.ipynb íŒ¨í„´)
    checker = GroundednessChecker(
        # LLMì„ í•¨ìˆ˜ ë‚´ì—ì„œ ì´ˆê¸°í™”
        llm=ChatOpenAI(model="gpt-4o-mini", temperature=0),
        target="question-retrieval"
    ).create()

    try:
        # ê´€ë ¨ì„± ì²´í¬
        response = checker.invoke({
            "question": state["current_question"],
            "context": state["retrieved_docs"]
        })

        relevance = response.score  # "yes" or "no"

        print(f" [ê´€ë ¨ì„± í‰ê°€] ê²°ê³¼: {relevance}")

        return {"is_relevant": relevance}

    except Exception as e:
        print(f" [ERROR] ê´€ë ¨ì„± í‰ê°€ ì‹¤íŒ¨: {e}")
        return {"is_relevant": "no"}


# ========== ë…¸ë“œ 5: ì§ˆë¬¸ ì¬ì‘ì„± ==========
def rewrite_question(state: MarketAnalysisState) -> Dict:
    """
    [ë…¸ë“œ 5: ì§ˆë¬¸ ì¬ì‘ì„±] ê´€ë ¨ì„± ë‚®ì„ ë•Œ ì§ˆë¬¸ ê°œì„ 

    Reference: 16-AgenticRAG/04-QueryRewrite.ipynb
    """

    print(f"\n [ì§ˆë¬¸ ì¬ì‘ì„±] ì¬ì‘ì„± ì‹œë„ ì¤‘... (íšŸìˆ˜: {state['rewrite_count'] + 1})")

    # Query Rewrite í”„ë¡¬í”„íŠ¸
    rewrite_prompt = get_query_rewrite_prompt()
    question_rewriter = (
        rewrite_prompt |
        ChatOpenAI(model="gpt-4o-mini", temperature=0) | # LLMì„ í•¨ìˆ˜ ë‚´ì—ì„œ ì´ˆê¸°í™”
        StrOutputParser()
    )

    try:
        # ì§ˆë¬¸ ì¬ì‘ì„±
        rewritten_question = question_rewriter.invoke({
            "question": state["current_question"]
        })

        print(f"âœ… [ì§ˆë¬¸ ì¬ì‘ì„±] ì™„ë£Œ")
        print(f"   ì›ë³¸: {state['current_question'][:50]}...")
        print(f"   ì¬ì‘ì„±: {rewritten_question[:50]}...")

        return {
            "current_question": rewritten_question,
            "rewrite_count": state["rewrite_count"] + 1
        }

    except Exception as e:
        print(f" [ERROR] ì§ˆë¬¸ ì¬ì‘ì„± ì‹¤íŒ¨: {e}")
        return {"rewrite_count": state["rewrite_count"] + 1}


# ========== ë…¸ë“œ 6: ì›¹ ê²€ìƒ‰ Fallback ==========
def web_search_fallback(state: MarketAnalysisState) -> Dict:
    """
    [ë…¸ë“œ 6: ì›¹ ê²€ìƒ‰] PDF ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ëŒ€ì•ˆ ê³„íš ì‹¤í–‰

    Reference: 16-AgenticRAG/03-WebSearch.ipynb
    """

    print(f"\nğŸŒ [ì›¹ ê²€ìƒ‰] PDFì—ì„œ ì •ë³´ ë¶€ì¡±, Tavily ì›¹ ê²€ìƒ‰ ì‹œë„ ì¤‘...")

    tavily_tool = TavilySearch(max_results=3)

    try:
        # ì›¹ ê²€ìƒ‰ ì‹¤í–‰
        search_results = tavily_tool.search(
            query=state["current_question"],
            topic="general",
            max_results=3,
            format_output=True
        )

        # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¬¸ì„œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        web_docs = "\n\n".join(search_results)

        print(f" [ì›¹ ê²€ìƒ‰] ì™„ë£Œ (ê²€ìƒ‰ ê²°ê³¼ {len(search_results)}ê°œ)")

        return {
            "retrieved_docs": web_docs,
            "fallback_attempted": True
        }

    except Exception as e:
        print(f" [ERROR] ì›¹ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return {
            "retrieved_docs": "",
            "fallback_attempted": True
        }


# ========== ë…¸ë“œ 7: ë‹µë³€ ìƒì„± ==========
def generate_answer(state: MarketAnalysisState) -> Dict:
    """
    [ë…¸ë“œ 7: ë‹µë³€ ìƒì„±] ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ ìƒì„± (ì¶œì²˜ í¬í•¨)

    Reference: 16-AgenticRAG/01-NaiveRAG.ipynb
    """

    print(f"\nğŸ’¬ [ë‹µë³€ ìƒì„±] LLM ë‹µë³€ ìƒì„± ì¤‘...")

    # ë‹µë³€ ìƒì„± í”„ë¡¬í”„íŠ¸ (ì‹œì¥ì„± í‰ê°€ íŠ¹í™” v0.3.0)
    answer_prompt = f"""ë„ˆëŠ” ë²¤ì²˜ìºí”¼íƒˆ íˆ¬ìì‹¬ì‚¬ì—­(Investment Analyst)ì´ì•¼. ìŠ¤íƒ€íŠ¸ì—…ì˜ ì‹œì¥ì„±ì„ í‰ê°€í•˜ê¸° ìœ„í•´ ì •í™•í•˜ê³  êµ¬ì²´ì ì¸ ë°ì´í„°ë¥¼ ì¶”ì¶œí•´ì•¼ í•´.

## í‰ê°€ ì›ì¹™
1. **ì •ëŸ‰ì  ë°ì´í„° ìš°ì„ **: ìˆ«ì, í¼ì„¼íŠ¸, ê¸ˆì•¡ ë“± êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ í•„ìˆ˜
2. **ë¹„êµ ê¸°ì¤€ ì œì‹œ**: ê²½ìŸì‚¬, ì—…ê³„ í‰ê· , ì„±ì¥ë¥  ë“± ìƒëŒ€ì  ìœ„ì¹˜ ëª…ì‹œ
3. **ì‹œê°„ í”„ë ˆì„ ëª…í™•í™”**: ì–¸ì œì˜ ë°ì´í„°ì¸ì§€, ë¯¸ë˜ ì „ë§ì€ ëª‡ ë…„ í›„ì¸ì§€ ëª…ì‹œ
4. **ì¶œì²˜ ì‹ ë¢°ì„±**: í˜ì´ì§€ ë²ˆí˜¸, ì„¹ì…˜ëª… ë°˜ë“œì‹œ í¬í•¨

## ì§ˆë¬¸
{state['current_question']}

## ë¬¸ì„œ
{state['retrieved_docs']}

## ë‹µë³€ í˜•ì‹ (ë°˜ë“œì‹œ ì¤€ìˆ˜)
- **í•µì‹¬ ë‹µë³€**: [1-2ì¤„ ìš”ì•½, êµ¬ì²´ì  ìˆ˜ì¹˜ í¬í•¨]
- **ìƒì„¸ ë¶„ì„**:
  - ì •ëŸ‰ ë°ì´í„°: [êµ¬ì²´ì  ìˆ«ì, ë‹¨ìœ„, ì‹œì ]
  - ë¹„êµ ë¶„ì„: [ê²½ìŸì‚¬/ì—…ê³„ ëŒ€ë¹„ ìœ„ì¹˜]
  - ì„±ì¥ ì „ë§: [í–¥í›„ ì˜ˆìƒ, ê·¼ê±°]
- **ì¶œì²˜**: [í˜ì´ì§€ ë²ˆí˜¸, ì„¹ì…˜ëª…]

[ì£¼ì˜] ë¬¸ì„œì— ì •ë³´ê°€ ì—†ìœ¼ë©´ "ë¬¸ì„œì—ì„œ í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ"ì´ë¼ê³  ëª…ì‹œí•˜ê³  ì¶”ì¸¡í•˜ì§€ ë§ˆ.
"""

    try:
        response = ChatOpenAI(model="gpt-4o-mini", temperature=0).invoke(answer_prompt)
        answer = response.content

        print(f" [ë‹µë³€ ìƒì„±] ì™„ë£Œ")
        print(f"   ë‹µë³€ ë¯¸ë¦¬ë³´ê¸°: {answer[:100]}...")

        # í˜„ì¬ ì§ˆë¬¸ì˜ í‚¤ ì¶”ì¶œ
        current_idx = state["current_question_idx"]
        question_key = state["sub_questions"][current_idx]["key"]

        # bessemer_answersì— ì €ì¥
        bessemer_answers = state["bessemer_answers"]
        bessemer_answers[question_key] = {
            "question": state["current_question"],
            "answer": answer,
            "rewrite_count": state["rewrite_count"],
            "fallback_used": state["fallback_attempted"],
            "status": "success"
        }

        return {
            "bessemer_answers": bessemer_answers,
            "current_question_idx": state["current_question_idx"] + 1  # ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ
        }

    except Exception as e:
        print(f" [ERROR] ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
        return {}


# ========== ë…¸ë“œ 8: ì§ˆë¬¸ ìŠ¤í‚µ (ì‹¤íŒ¨ ì¼€ì´ìŠ¤ ì²˜ë¦¬) ==========
def skip_question(state: MarketAnalysisState) -> Dict:
    """
    [ë…¸ë“œ 8: ì§ˆë¬¸ ìŠ¤í‚µ] ì›¹ ê²€ìƒ‰ë„ ì‹¤íŒ¨í•œ ê²½ìš° ë‹µë³€ ë¶ˆê°€ ì²˜ë¦¬

    ê°œì„ ì : v0.2.1ì—ì„œ ì¶”ê°€ëœ ì•ˆì „ì¥ì¹˜
    """

    print(f"\n [ì§ˆë¬¸ ìŠ¤í‚µ] ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ë‹µë³€ ë¶ˆê°€ ì²˜ë¦¬")

    # í˜„ì¬ ì§ˆë¬¸ì˜ í‚¤ ì¶”ì¶œ
    current_idx = state["current_question_idx"]
    question_key = state["sub_questions"][current_idx]["key"]

    # bessemer_answersì— ì‹¤íŒ¨ ê¸°ë¡
    bessemer_answers = state["bessemer_answers"]
    bessemer_answers[question_key] = {
        "question": state["current_question"],
        "answer": "ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ë‹µë³€ ë¶ˆê°€",
        "rewrite_count": state["rewrite_count"],
        "fallback_used": state["fallback_attempted"],
        "status": "failed"
    }

    return {
        "bessemer_answers": bessemer_answers,
        "current_question_idx": state["current_question_idx"] + 1  # ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ
    }


# ========== ë…¸ë“œ 9: Scorecard ì ìˆ˜ ê³„ì‚° ==========
def calculate_scorecard(state: MarketAnalysisState) -> Dict:
    """
    [ë…¸ë“œ 9: ì ìˆ˜ ê³„ì‚°] Scorecard Methodë¡œ ì‹œì¥ì„± ì ìˆ˜ ì‚°ì¶œ

    Reference: í”„ë¡œì íŠ¸ ê°€ì´ë“œ PDF - Scorecard Method
    """

    print("\n" + "="*60)
    print("ğŸ“Š [Scorecard] ì‹œì¥ì„± ì ìˆ˜ ê³„ì‚° ì¤‘...")
    print("="*60)

    # Bessemer ë‹µë³€ ì¢…í•©
    bessemer_answers = state["bessemer_answers"]

    market_data = f"""
[ì‹œì¥ ê·œëª¨ (TAM)]
{bessemer_answers.get('market_size', {}).get('answer', 'N/A')}

[í•´ê²°í•˜ëŠ” ë¬¸ì œ]
{bessemer_answers.get('market_problem', {}).get('answer', 'N/A')}

[ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸]
{bessemer_answers.get('business_model', {}).get('answer', 'N/A')}
"""

    # Scorecard í‰ê°€ í”„ë¡¬í”„íŠ¸
    scorecard_prompt = get_scorecard_prompt()
    evaluation_prompt = scorecard_prompt.format(market_data=market_data)

    try:
        response = ChatOpenAI(model="gpt-4o-mini", temperature=0).invoke(evaluation_prompt)
        evaluation_text = response.content

        # ì ìˆ˜ íŒŒì‹± (ì •ê·œí‘œí˜„ì‹)
        score_match = re.search(r"ì ìˆ˜:\s*(\d+)ì ", evaluation_text)
        market_score = int(score_match.group(1)) if score_match else 100

        # ê·¼ê±° ì¶”ì¶œ
        reasoning_match = re.search(r"ê·¼ê±°:(.*)", evaluation_text, re.DOTALL)
        reasoning = reasoning_match.group(1).strip() if reasoning_match else evaluation_text

        print(f"\nâœ… [Scorecard] ê³„ì‚° ì™„ë£Œ")
        print(f"   ì‹œì¥ì„± ì ìˆ˜: {market_score}ì  (ë¹„ì¤‘ 25%)")
        print(f"   ê·¼ê±°: {reasoning[:100]}...")

        scorecard_result = {
            "market_score": market_score,
            "weight_percentage": 25,
            "weighted_contribution": market_score * 0.25,
            "reasoning": reasoning,
            "evaluation_method": "Scorecard Valuation Method",
            "evaluation_date": "2025-04-16"
        }

        return {"scorecard_result": scorecard_result}

    except Exception as e:
        print(f" [ERROR] Scorecard ê³„ì‚° ì‹¤íŒ¨: {e}")
        return {
            "scorecard_result": {
                "market_score": 100,
                "error": str(e)
            }
        }


# ========== ë…¸ë“œ 9.5: ì‚°ì—… ì¸ì‚¬ì´íŠ¸ ë¶„ì„ (v0.3.0) ==========
def analyze_industry_insights(state: MarketAnalysisState) -> Dict:
    """
    [ë…¸ë“œ 9.5: ì‚°ì—… ì¸ì‚¬ì´íŠ¸ ë¶„ì„] ìˆ˜ì§‘ëœ ë‰´ìŠ¤ë¥¼ LLMìœ¼ë¡œ ìš”ì•½ ë¶„ì„

    ìœ„ì¹˜: calculate_scorecard ì§í›„, finalize_report ì§ì „

    ì‘ì—…:
    1. ìˆ˜ì§‘ëœ ë‰´ìŠ¤ë¥¼ LLMì—ê²Œ ì œê³µ
    2. íˆ¬ì ê´€ì ì—ì„œ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ 3ê°€ì§€ ì¶”ì¶œ
    3. Bessemer ë‹µë³€ê³¼ ì—°ê²°í•˜ì—¬ ì‹œì¥ íƒ€ì´ë° í‰ê°€
    """

    print("\n" + "="*60)
    print(" [MarketAgent] ì‚°ì—… ì¸ì‚¬ì´íŠ¸ ë¶„ì„ ì‹œì‘")
    print("="*60)

    industry_news = state.get("industry_news", {})
    industry_category = state.get("industry_category", "Unknown")
    bessemer_answers = state["bessemer_answers"]

    # ë‰´ìŠ¤ê°€ ì—†ìœ¼ë©´ ìŠ¤í‚µ
    if not industry_news or not industry_news.get("news_categories"):
        print(" [WARNING] ìˆ˜ì§‘ëœ ë‰´ìŠ¤ê°€ ì—†ì–´ ì¸ì‚¬ì´íŠ¸ ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return {
            "industry_insights": {
                "summary": "ì‚°ì—… ë‰´ìŠ¤ ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ì¸ì‚¬ì´íŠ¸ ë¶„ì„ ë¶ˆê°€",
                "news_count": 0,
                "analysis_date": industry_news.get("search_date", "N/A")
            }
        }

    # ë‰´ìŠ¤ í…ìŠ¤íŠ¸ í†µí•©
    all_news_text = []
    for category, news_list in industry_news["news_categories"].items():
        if news_list:
            all_news_text.append(f"### {category.replace('_', ' ').title()}")
            all_news_text.extend(news_list[:3])  # ê° ì¹´í…Œê³ ë¦¬ì—ì„œ ìµœëŒ€ 3ê°œë§Œ

    news_context = "\n\n".join(all_news_text)

    # Bessemer ë‹µë³€ ìš”ì•½
    market_size_answer = bessemer_answers.get('market_size', {}).get('answer', 'N/A')[:200]
    differentiation_answer = bessemer_answers.get('differentiation', {}).get('answer', 'N/A')[:200]

    # LLM í”„ë¡¬í”„íŠ¸
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

    prompt = f"""ë„ˆëŠ” ë²¤ì²˜ íˆ¬ì ì „ë¬¸ê°€ì•¼. ì•„ë˜ ì‚°ì—… ë‰´ìŠ¤ë¥¼ ë¶„ì„í•˜ê³ , íˆ¬ì ê´€ì ì—ì„œ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ 3ê°€ì§€ë¥¼ ì¶”ì¶œí•´ì¤˜.

## ë¶„ì„ ëŒ€ìƒ ìŠ¤íƒ€íŠ¸ì—… ì •ë³´
- ì‚°ì—…: {industry_category}
- ì‹œì¥ ê·œëª¨: {market_size_answer}
- ê²½ìŸ ìš°ìœ„: {differentiation_answer}

## ìµœê·¼ 3ì¼ ì‚°ì—… ë‰´ìŠ¤
{news_context[:4000]}

## ì¶œë ¥ í˜•ì‹ (ë°˜ë“œì‹œ ì¤€ìˆ˜)
**í•µì‹¬ ì¸ì‚¬ì´íŠ¸ 1**: [1-2ì¤„ë¡œ ìš”ì•½]
**í•µì‹¬ ì¸ì‚¬ì´íŠ¸ 2**: [1-2ì¤„ë¡œ ìš”ì•½]
**í•µì‹¬ ì¸ì‚¬ì´íŠ¸ 3**: [1-2ì¤„ë¡œ ìš”ì•½]

**íˆ¬ì íƒ€ì´ë° í‰ê°€**: [í˜„ì¬ ì‹œì¥ ìƒí™©ì´ ì´ ìŠ¤íƒ€íŠ¸ì—… íˆ¬ìì— ìœ ë¦¬í•œì§€ 2ì¤„ë¡œ í‰ê°€]
"""

    try:
        insights = llm.invoke(prompt).content

        print(f"\nâœ… [ì¸ì‚¬ì´íŠ¸ ë¶„ì„ ì™„ë£Œ]")
        print(f"   {insights[:150]}...")

        return {
            "industry_insights": {
                "summary": insights,
                "news_count": sum(len(v) for v in industry_news["news_categories"].values()),
                "analysis_date": industry_news["search_date"]
            }
        }

    except Exception as e:
        print(f" [ERROR] ì¸ì‚¬ì´íŠ¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
        return {
            "industry_insights": {
                "summary": f"ì¸ì‚¬ì´íŠ¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                "news_count": 0,
                "analysis_date": industry_news.get("search_date", "N/A")
            }
        }


# ========== ë…¸ë“œ 10: ìµœì¢… ë³´ê³ ì„œ ìƒì„± ==========
def finalize_report(state: MarketAnalysisState) -> Dict:
    """
    [ë…¸ë“œ 10: ìµœì¢… ë³´ê³ ] ëª¨ë“  ë¶„ì„ ê²°ê³¼ë¥¼ JSON ë³´ê³ ì„œë¡œ êµ¬ì¡°í™”

    Reference: 21-Agent/21-Multi-ReportAgent.ipynb
    """

    print("\n" + "="*60)
    print("ğŸ“„ [ìµœì¢… ë³´ê³ ì„œ] JSON ë³´ê³ ì„œ ìƒì„± ì¤‘...")
    print("="*60)

    # ê¸°ë³¸ ë³´ê³ ì„œ êµ¬ì¡°
    final_report = {
        "startup_name": state["startup_name"],
        "analysis_type": "Market Analysis (ì‹œì¥ì„± í‰ê°€)",
        "analysis_date": "2025-04-16",
        "bessemer_checklist": state["bessemer_answers"],
        "scorecard_method": state["scorecard_result"],
        "summary": {
            "market_score": state["scorecard_result"].get("market_score", 0),
            "weight_percentage": 25,
            "success_count": sum(
                1 for ans in state["bessemer_answers"].values()
                if ans.get("status") == "success"
            ),
            "failed_count": sum(
                1 for ans in state["bessemer_answers"].values()
                if ans.get("status") == "failed"
            )
        }
    }

    # ğŸ†• v0.3.0: ì‚°ì—… ë‰´ìŠ¤ ì¸í…”ë¦¬ì „ìŠ¤ ì„¹ì…˜ ì¶”ê°€
    industry_news = state.get("industry_news", {})
    industry_insights = state.get("industry_insights", {})

    if industry_news and industry_news.get("news_categories"):
        # ê° ì¹´í…Œê³ ë¦¬ì—ì„œ ìƒìœ„ 3ê°œ ë‰´ìŠ¤ë§Œ í¬í•¨
        key_trends = industry_news["news_categories"].get("market_trends", [])[:3]
        competitor_activity = industry_news["news_categories"].get("competitor_moves", [])[:3]
        regulatory_updates = industry_news["news_categories"].get("regulatory_changes", [])[:2]

        final_report["industry_intelligence"] = {
            "industry_category": state.get("industry_category", "Unknown"),
            "news_summary": industry_insights.get("summary", "ì¸ì‚¬ì´íŠ¸ ë¶„ì„ ì—†ìŒ"),
            "total_news_analyzed": industry_insights.get("news_count", 0),
            "key_trends": key_trends,
            "competitor_activity": competitor_activity,
            "regulatory_updates": regulatory_updates,
            "search_date": industry_news.get("search_date", "N/A")
        }
    else:
        # ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°
        final_report["industry_intelligence"] = {
            "industry_category": state.get("industry_category", "Unknown"),
            "news_summary": "ì‚°ì—… ë‰´ìŠ¤ ë°ì´í„° ì—†ìŒ",
            "total_news_analyzed": 0,
            "key_trends": [],
            "competitor_activity": [],
            "regulatory_updates": [],
            "search_date": "N/A"
        }

    print(f"\nâœ… [ìµœì¢… ë³´ê³ ì„œ] ìƒì„± ì™„ë£Œ")
    print(f"   ì„±ê³µ: {final_report['summary']['success_count']}ê°œ ì§ˆë¬¸")
    print(f"   ì‹¤íŒ¨: {final_report['summary']['failed_count']}ê°œ ì§ˆë¬¸")
    print(f"   ì‹œì¥ì„± ì ìˆ˜: {final_report['summary']['market_score']}ì ")
    print(f"   ì‚°ì—… ë‰´ìŠ¤: {final_report['industry_intelligence']['total_news_analyzed']}ê°œ ë¶„ì„")

    return {"final_report": final_report}
